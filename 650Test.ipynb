{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "650Test.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb_jZkNee4D0",
        "outputId": "0a6fade7-dd8a-4edc-bc82-704215140074"
      },
      "source": [
        "!pip install python-terrier"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-terrier\n",
            "  Downloading python-terrier-0.7.1.tar.gz (95 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 30 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 40 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 51 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 61 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 71 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 81 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 95 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.1.5)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from python-terrier) (4.62.3)\n",
            "Collecting pyjnius~=1.3.0\n",
            "  Downloading pyjnius-1.3.0-cp37-cp37m-manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 59.2 MB/s \n",
            "\u001b[?25hCollecting matchpy\n",
            "  Downloading matchpy-0.5.5-py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.0)\n",
            "Collecting deprecation\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting chest\n",
            "  Downloading chest-0.2.3.tar.gz (9.6 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.1.0)\n",
            "Collecting nptyping\n",
            "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.7/dist-packages (from python-terrier) (8.12.0)\n",
            "Collecting ir_datasets>=0.3.2\n",
            "  Downloading ir_datasets-0.5.0-py3-none-any.whl (255 kB)\n",
            "\u001b[K     |████████████████████████████████| 255 kB 78.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.11.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.10.2)\n",
            "Collecting ir_measures>=0.2.0\n",
            "  Downloading ir_measures-0.2.1.tar.gz (36 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.3.4)\n",
            "Collecting warc3-wet-clueweb09>=0.2.5\n",
            "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
            "Collecting lz4>=3.1.1\n",
            "  Downloading lz4-3.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 73.3 MB/s \n",
            "\u001b[?25hCollecting pyautocorpus>=0.1.1\n",
            "  Downloading pyautocorpus-0.1.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 91.3 MB/s \n",
            "\u001b[?25hCollecting warc3-wet>=0.2.3\n",
            "  Downloading warc3_wet-0.2.3-py3-none-any.whl (13 kB)\n",
            "Collecting pyyaml>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 82.4 MB/s \n",
            "\u001b[?25hCollecting ijson>=3.1.3\n",
            "  Downloading ijson-3.1.4-cp37-cp37m-manylinux2010_x86_64.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 93.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from ir_datasets>=0.3.2->python-terrier) (4.6.3)\n",
            "Collecting zlib-state>=0.1.3\n",
            "  Downloading zlib_state-0.1.3-cp37-cp37m-manylinux2010_x86_64.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting lxml>=4.5.2\n",
            "  Downloading lxml-4.6.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 63.2 MB/s \n",
            "\u001b[?25hCollecting trec-car-tools>=2.5.4\n",
            "  Downloading trec_car_tools-2.5.4-py3-none-any.whl (8.1 kB)\n",
            "Collecting pytrec-eval-terrier==0.5.1\n",
            "  Downloading pytrec_eval_terrier-0.5.1-cp37-cp37m-manylinux2010_x86_64.whl (291 kB)\n",
            "\u001b[K     |████████████████████████████████| 291 kB 89.6 MB/s \n",
            "\u001b[?25hCollecting cwl-eval>=1.0.10\n",
            "  Downloading cwl-eval-1.0.10.tar.gz (31 kB)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyjnius~=1.3.0->python-terrier) (1.15.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from pyjnius~=1.3.0->python-terrier) (0.29.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->python-terrier) (2021.10.8)\n",
            "Collecting cbor>=1.0.0\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from chest->python-terrier) (1.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation->python-terrier) (21.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->python-terrier) (2.0.1)\n",
            "Collecting multiset<3.0,>=2.0\n",
            "  Downloading multiset-2.1.1-py2.py3-none-any.whl (8.8 kB)\n",
            "Collecting typish>=1.7.0\n",
            "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation->python-terrier) (3.0.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->python-terrier) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->python-terrier) (2.8.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->python-terrier) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->python-terrier) (3.0.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->python-terrier) (0.5.2)\n",
            "Building wheels for collected packages: python-terrier, ir-measures, cwl-eval, cbor, warc3-wet-clueweb09, chest, wget\n",
            "  Building wheel for python-terrier (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-terrier: filename=python_terrier-0.7.1-py3-none-any.whl size=102452 sha256=122cf11bd49ce3b80b8c34fa92eff8d17d18ddf07c503c72dab847032959a117\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/9a/c8/1c2d9ec6a1494bb54f47e0d2627b5ed7b2de704b66723d3417\n",
            "  Building wheel for ir-measures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ir-measures: filename=ir_measures-0.2.1-py3-none-any.whl size=46421 sha256=bda6f61f3c420bd6f58b61e6caed6d0922cdf0a7624215f290027a74edfe86b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/a4/34/d0b2e6c329f3d0fab3d3c3ed296b963cee47872811acdc3628\n",
            "  Building wheel for cwl-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cwl-eval: filename=cwl_eval-1.0.10-py3-none-any.whl size=37795 sha256=6a185289ee3b23c258cadeba572ef86e1c2aeae2e1656a63e9d42a518d04c773\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/e9/ff/d2b6d72d9feb0d0b1b11aacfaf5cd866717034615c2d194093\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp37-cp37m-linux_x86_64.whl size=51310 sha256=7052f17fcdbaf38c4dcc51f483e45fac1dfb1e8346fa9ead0551eaffccf4f8f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/77/49/c9c2c8dc5848502e606e8579d0bbda18b850fb056a6c62239d\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18921 sha256=f8a9725557dcf9219ba181a23e5eca442e0287ffaf296f84a1f46fe77ac57739\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/d4/3c/7c2b0c3d400ad744e4db69f2fde166655da2ed2198bfc02db6\n",
            "  Building wheel for chest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chest: filename=chest-0.2.3-py3-none-any.whl size=7632 sha256=2556468c14afb70e78da7c2a212cbb40933372db6c4e5262985ab6f49cd76c6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/f5/b9/c436e11300809e6b40d46a5d2592fb0bff89e0712f2e878dc7\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=c53c1933c7eb95fd167f1973032825f132cd267497763c2055b6867939fa65ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built python-terrier ir-measures cwl-eval cbor warc3-wet-clueweb09 chest wget\n",
            "Installing collected packages: cbor, zlib-state, warc3-wet-clueweb09, warc3-wet, typish, trec-car-tools, pyyaml, pytrec-eval-terrier, pyautocorpus, multiset, lz4, lxml, ijson, deprecation, cwl-eval, wget, pyjnius, nptyping, matchpy, ir-measures, ir-datasets, chest, python-terrier\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed cbor-1.0.0 chest-0.2.3 cwl-eval-1.0.10 deprecation-2.1.0 ijson-3.1.4 ir-datasets-0.5.0 ir-measures-0.2.1 lxml-4.6.4 lz4-3.1.10 matchpy-0.5.5 multiset-2.1.1 nptyping-1.4.4 pyautocorpus-0.1.6 pyjnius-1.3.0 python-terrier-0.7.1 pytrec-eval-terrier-0.5.1 pyyaml-6.0 trec-car-tools-2.5.4 typish-1.9.3 warc3-wet-0.2.3 warc3-wet-clueweb09-0.2.5 wget-3.2 zlib-state-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tb9esiggnWP"
      },
      "source": [
        "import altair as alt\n",
        "import pandas as pd\n",
        "import pyterrier as pt\n",
        "import os\n",
        "from pyterrier.measures import *\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgN3cq2ngp7-"
      },
      "source": [
        "debugging = 1\n",
        "class Model:\n",
        "    RANK_CUTOFF = 100\n",
        "    SEED = 42\n",
        "    QUERY_CUTOFF = 30\n",
        "    def init_data(self, path):\n",
        "        foodresults = pd.read_csv(path, encoding=\"latin-1\")\n",
        "        data=[]\n",
        "        foodresults[\"docno\"] = range(0,len(foodresults))\n",
        "        foodresults[\"recipe_id\"] = range(0,len(foodresults))\n",
        "        foodresults.head(5)\n",
        "        for index,row in foodresults.iterrows():\n",
        "            # docno = \"d\"+str(row[\"docno\"])\n",
        "            recipe_id = str(row[\"recipe_id\"])\n",
        "            recipe_name = \" \".join(re.findall(\"[a-zA-Z]+\", row[\"name\"]))\n",
        "            ingredients = \" \".join(re.findall(\"[a-zA-Z]+\", str(row[\"ingredients\"])))\n",
        "            recipe = \" \".join(re.findall(\"[a-zA-Z]+\", str(row[\"recipe\"])))\n",
        "            rate = str(float(row[\"rate\"]))\n",
        "            views = str(int(row[\"views\"]))\n",
        "            description = \" \".join(re.findall(\"[a-zA-Z]+\", row[\"description\"]))\n",
        "            keywords = \" \".join(re.findall(\"[a-zA-Z]+\", str(row[\"keywords\"])))\n",
        "            calories = row[\"calories\"]\n",
        "            fatContent = row[\"fatContent\"]\n",
        "            proteinContent = row[\"proteinContent\"]\n",
        "            url = row[\"url\"]\n",
        "\n",
        "            original_recipe_name = str(row['name'])\n",
        "            original_ingredients = str(row[\"ingredients\"])\n",
        "            original_recipe = str(row[\"recipe\"])\n",
        "            original_description = str(row[\"description\"])\n",
        "            original_keywords = str(row[\"keywords\"])\n",
        "\n",
        "            data.append([recipe_id,recipe_name,ingredients,recipe,\n",
        "                        rate,views,description,keywords,calories,fatContent,proteinContent, url, original_recipe_name, \n",
        "                        original_ingredients, original_recipe, original_description, original_keywords])\n",
        "        self.df = pd.DataFrame(data,columns=[\"docno\",\"recipe_name\",\"ingredients\",\"recipe\",\n",
        "                    \"rate\",\"views\",\"description\",\"keywords\",\"calories\",\"fatContent\",\"proteinContent\", \"url\", \n",
        "                    \"original_recipe_name\", \"original_ingredients\",\"original_recipe\", \"original_description\",\n",
        "                    \"original_keywords\"])\n",
        "        if debugging == 1:\n",
        "          print(\"init_data finished\")\n",
        "\n",
        "    \n",
        "    def create_index(self):\n",
        "        self.index_dir = \"./docs_index\"\n",
        "        indexer = pt.DFIndexer(self.index_dir, overwrite=True)\n",
        "        index_ref = indexer.index(self.df[\"recipe\"], self.df[\"docno\"], self.df[\"recipe_name\"], self.df[\"keywords\"], \n",
        "                            self.df[\"description\"], self.df[\"ingredients\"], self.df[\"rate\"], self.df[\"views\"], self.df[\"url\"])\n",
        "        # index_ref.toString()\n",
        "        self.index = pt.IndexFactory.of(index_ref)\n",
        "        if debugging == 1:\n",
        "          print(\"create_index finished\")\n",
        "\n",
        "    def get_topic_qrel(self, path_topic, path_qrel):\n",
        "        topics = pd.read_csv(path_topic)\n",
        "        qrels = pd.read_csv(path_qrel)\n",
        "        qrels = qrels.drop(columns=[\"iteration\"])\n",
        "        topics[\"qid\"] = topics[\"qid\"].astype(str)\n",
        "        qrels[\"qid\"] = qrels[\"qid\"].astype(str)\n",
        "        qrels[\"docno\"] = qrels[\"docno\"].astype(str)\n",
        "        self.topics = topics\n",
        "        self.qrels = qrels\n",
        "        if debugging == 1:\n",
        "          print(\"get_topic_qrel finished\")\n",
        "\n",
        "    def init_pymodels(self):\n",
        "        self.bm25 = pt.BatchRetrieve(self.index, wmodel=\"BM25\")\n",
        "        self.qe = pt.rewrite.Bo1QueryExpansion(self.index)\n",
        "        self.ltr_feats = (self.bm25 % self.RANK_CUTOFF) >> pt.text.get_text(self.index, [\"recipe_name\",\"keywords\",\"description\",\"ingredients\",\"rate\",\"views\"]) >> (\n",
        "            pt.transformer.IdentityTransformer()\n",
        "            **\n",
        "            (self.bm25 >> self.qe >> self.bm25)\n",
        "            **\n",
        "            (pt.text.scorer(body_attr=\"recipe_name\", takes='docs', wmodel='BM25'))\n",
        "            ** # score of title (not originally indexed)\n",
        "            (pt.text.scorer(body_attr=\"keywords\", takes='docs', wmodel='BM25'))\n",
        "            ** \n",
        "            (pt.text.scorer(body_attr=\"description\", takes='docs', wmodel='BM25'))\n",
        "            ** \n",
        "            (pt.text.scorer(body_attr=\"ingredients\", takes='docs', wmodel='BM25'))\n",
        "            **\n",
        "            pt.apply.doc_score(lambda row: float(row[\"rate\"]))\n",
        "            **\n",
        "            pt.apply.doc_score(lambda row: int(row[\"views\"]))\n",
        "            # **\n",
        "            # pt.BatchRetrieve(self.index, wmodel=\"CoordinateMatch\")\n",
        "        )\n",
        "        self.fnames=[\"bm25\", \"qe\", \"bm25_recipe_name\", \"bm25_keywords\", \"bm25_description\", \"bm25_ingredients\", \"rate\", \"views\"]\n",
        "        lmart_l = lgb.LGBMRanker(\n",
        "            task=\"train\",\n",
        "            silent=False,\n",
        "            min_data_in_leaf=1,\n",
        "            min_sum_hessian_in_leaf=1,\n",
        "            max_bin=255,\n",
        "            num_leaves=31,\n",
        "            objective=\"lambdarank\",\n",
        "            metric=\"ndcg\",\n",
        "            ndcg_eval_at=[10],\n",
        "            ndcg_at=[10],\n",
        "            eval_at=[10],\n",
        "            learning_rate= .1,\n",
        "            importance_type=\"gain\",\n",
        "            num_iterations=100,\n",
        "            early_stopping_rounds=5\n",
        "        )\n",
        "        self.lmart_x_pipe = self.ltr_feats >> pt.ltr.apply_learned_model(lmart_l, form=\"ltr\", fit_kwargs={'eval_at':[10]})\n",
        "        if debugging == 1:\n",
        "          print(\"init_pymodels finished\")\n",
        "\n",
        "    def train_model(self):\n",
        "        tr_va_topics, test_topics = train_test_split(self.topics, test_size=0.15, random_state=self.SEED)\n",
        "        train_topics, valid_topics =  train_test_split(tr_va_topics, test_size=0.17, random_state=self.SEED)\n",
        "        self.lmart_x_pipe.fit(train_topics, self.qrels, valid_topics, self.qrels)\n",
        "        if debugging == 1:\n",
        "          print(\"train_model finished\")\n",
        "\n",
        "    def __init__(self, path_data, path_topic, path_qrel):\n",
        "        self.init_data(path_data)\n",
        "        self.create_index()\n",
        "        self.get_topic_qrel(path_topic, path_qrel)\n",
        "        self.init_pymodels()\n",
        "        self.train_model()\n",
        "        if debugging == 1:\n",
        "          print(\"init finished\")\n",
        "\n",
        "    def get_query_results(self, query):\n",
        "        query_results = self.lmart_x_pipe(query).head(self.QUERY_CUTOFF)[\"docno\"].to_list()\n",
        "        results = []\n",
        "        rank = 0\n",
        "        for result in query_results:\n",
        "            result_dict = {'docno': result, \n",
        "            'recipe_name': self.df[self.df['docno'] == result]['original_recipe_name'].to_list()[0],\n",
        "            'ingredients': self.df[self.df['docno'] == result]['original_ingredients'].to_list()[0],\n",
        "            'recipe': self.df[self.df['docno'] == result]['original_recipe'].to_list()[0],\n",
        "            'rate': self.df[self.df['docno'] == result]['rate'].to_list()[0],\n",
        "            'views': self.df[self.df['docno'] == result]['views'].to_list()[0],\n",
        "            'description': self.df[self.df['docno'] == result]['original_description'].to_list()[0],\n",
        "            'calories': self.df[self.df['docno'] == result]['calories'].to_list()[0],\n",
        "            'fatContent': self.df[self.df['docno'] == result]['fatContent'].to_list()[0],\n",
        "            'proteinContent': self.df[self.df['docno'] == result]['proteinContent'].to_list()[0],\n",
        "            'url': self.df[self.df['docno'] == result]['url'].to_list()[0],\n",
        "            'rank': rank}\n",
        "            results.append(result_dict)\n",
        "            rank += 1\n",
        "        return results"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAxOIOVOgt-3"
      },
      "source": [
        "def pyterrier_init():\n",
        "    if not pt.started():\n",
        "      pt.init()\n",
        "\n",
        "def initialize():\n",
        "    pyterrier_init()\n",
        "\n",
        "def main():\n",
        "  initialize()\n",
        "  model = Model(\"foodresults.csv\", \"topics.csv\", 'qrel.csv') \n",
        "  return model"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1Jx6_Oxg4p9"
      },
      "source": [
        "model = main()\n",
        "# examples of how to use\n",
        "# query = \"tomato\"\n",
        "# SFR = model.get_query_results(query)\n",
        "# query_df = pd.DataFrame(SFR)\n",
        "# query_df.head(10)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVQZsEKog4w-"
      },
      "source": [
        ""
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBE50ERbkU1G"
      },
      "source": [
        ""
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwPZnH_-s7XF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}